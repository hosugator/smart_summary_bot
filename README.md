## 📰 Smart Summary Bot: 뉴스 크롤러

이 프로젝트는 네이버 뉴스 웹사이트에서 주요 섹션의 헤드라인 기사를 자동으로 크롤링하고 CSV 파일로 저장하는 파이썬 웹 크롤러입니다. 추후 모델이 기사 내용을 요약하는 데 사용될 데이터를 수집하기 위해 개발되었습니다.

-----

### **프로젝트 개요 (Project Overview)**

`crawler.py` 파일은 웹 크롤링을 위한 핵심 로직을 담고 있으며, `test_crawler.py`는 크롤러의 기능이 정상적으로 작동하는지 확인하기 위한 테스트 코드를 포함합니다.

-----

### **주요 기능 (Key Features)**

  * **다중 섹션 크롤링**: 정치, 경제, 사회, 생활/문화, IT/과학, 세계 등 네이버 뉴스의 다양한 섹션에서 기사 데이터를 수집합니다.
  * **데이터 추출**: 각 기사에서 제목, URL, 언론사, 그리고 크롤링한 날짜를 추출합니다.
  * **CSV 파일 저장**: 크롤링한 모든 데이터를 `naver_news_articles.csv` 파일에 저장하여 쉽게 접근하고 사용할 수 있도록 합니다.

-----

### **설치 (Installation)**

이 프로젝트를 실행하기 위해 필요한 파이썬 라이브러리를 설치합니다.

```sh
pip install -r requirements.txt
```

-----

### **사용법 (Usage)**

프로젝트의 루트 디렉터리에서 다음 명령어를 실행하여 크롤링을 시작할 수 있습니다.

```sh
python crawler/crawler.py
```

명령어가 실행되면, 각 뉴스 섹션의 기사를 크롤링한 후 모든 데이터가 **`naver_news_articles.csv`** 파일에 저장됩니다.

-----

### **테스트 (Testing)**

`pytest`를 사용하여 크롤러의 기능을 테스트할 수 있습니다. 테스트를 실행하기 전에 필요한 라이브러리가 모두 설치되었는지 확인하세요.

```sh
pytest tests/test_crawler.py
```

테스트 코드는 다음과 같은 항목을 검증합니다:

  * **파일 생성**: CSV 저장 함수가 올바르게 파일을 생성하는지 확인합니다.
  * **내용 검증**: 저장된 CSV 파일에 예상한 데이터가 올바르게 포함되어 있는지 확인합니다.
