# # modeler/model.py


# TensorFlow/PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„± ë¬¸ì œ ë°œìƒ 
# ë¹„êµì  í˜¸í™˜ì„±ì´ ì¢‹ì€ Scikit-learn ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
# í…ìŠ¤íŠ¸ ë¶„ë¥˜ì— ìµœì í™”(ë‹¨ì–´ë³„)
# CPUì— ìµœì í™”
import numpy as np
import pickle
import logging
import json
from datetime import datetime
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì • (Macìš©)
plt.rcParams['font.family'] = ['Arial Unicode MS', 'AppleGothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

logger = logging.getLogger(__name__)


class M4TransformerModel:
    """M4 Mac ìµœì í™” ë¶„ë¥˜ ëª¨ë¸ (TensorFlow ì—†ì´ RandomForest ì‚¬ìš©)"""
    
    def __init__(self, n_estimators=200, max_depth=10):
        self.model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_split=5, 
            random_state=42,
            n_jobs=-1           # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
        )
        self.kmeans = None
        self.is_fitted = False
        self.config = {
            'n_estimators': n_estimators,
            'max_depth': max_depth,
            'model_type': 'RandomForest',
            'timestamp': datetime.now().isoformat()
        }
        print(f"ğŸ§  M4 Mac ìµœì í™” RandomForest ëª¨ë¸ ì´ˆê¸°í™”")
        print(f"   ì„¤ì •: {n_estimators} trees, max_depth={max_depth}")
    
    def load_embeddings(self, embeddings_path, data_path=None):
        """ì €ì¥ëœ ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
        embeddings = np.load(embeddings_path)
        logger.info(f"ì„ë² ë”© ë¡œë“œ: {embeddings.shape}")
        print(f"ğŸ“Š ì„ë² ë”© ë¡œë“œ: {embeddings.shape}")
        
        metadata = None
        if data_path and os.path.exists(data_path):
            with open(data_path, 'rb') as f:
                metadata = pickle.load(f)
            logger.info(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(metadata['texts'])}ê°œ")
            print(f"ğŸ“„ ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(metadata['texts'])}ê°œ í…ìŠ¤íŠ¸")
        
        return embeddings, metadata
    
    def create_labels(self, embeddings, n_clusters=8):
        """K-meansë¡œ ë¼ë²¨ ìƒì„± (ë¹„ì§€ë„ í•™ìŠµ)"""
        print(f"ğŸ·ï¸  K-means í´ëŸ¬ìŠ¤í„°ë§ ({n_clusters}ê°œ í´ëŸ¬ìŠ¤í„°)...")
        
        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        labels = self.kmeans.fit_predict(embeddings)
        
        unique, counts = np.unique(labels, return_counts=True)
        print(f"   í´ëŸ¬ìŠ¤í„° ë¶„í¬: {dict(zip(unique, counts))}")
        logger.info(f"í´ëŸ¬ìŠ¤í„° ë¶„í¬: {dict(zip(unique, counts))}")
        
        return labels
    
    def prepare_data(self, embeddings, labels=None, test_size=0.2):
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„"""
        # ë¼ë²¨ì´ ì—†ìœ¼ë©´ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ìƒì„±
        if labels is None:
            n_clusters = min(10, len(embeddings) // 10)
            labels = self.create_labels(embeddings, n_clusters)
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            embeddings, labels, test_size=test_size, random_state=42, 
            stratify=labels
        )
        
        print(f"ğŸ“š ë°ì´í„° ë¶„í• : í›ˆë ¨ {len(X_train)}, í…ŒìŠ¤íŠ¸ {len(X_test)}")
        logger.info(f"ë°ì´í„° ë¶„í• : í›ˆë ¨ {len(X_train)}, í…ŒìŠ¤íŠ¸ {len(X_test)}")
        
        return X_train, X_test, y_train, y_test
    
    def fit(self, X, y):
        """ëª¨ë¸ í›ˆë ¨ (sklearn í˜¸í™˜)"""
        return self.train(X, y)
    
    def train(self, X_train, y_train, X_test=None, y_test=None):
        """ëª¨ë¸ í›ˆë ¨"""
        print(f"ğŸ“š ëª¨ë¸ í›ˆë ¨ ì‹œì‘: {X_train.shape} â†’ {len(np.unique(y_train))} í´ë˜ìŠ¤")
        
        try:
            self.model.fit(X_train, y_train)
            self.is_fitted = True
            
            # íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸
            importances = self.model.feature_importances_
            print(f"âœ… í›ˆë ¨ ì™„ë£Œ (í‰ê·  íŠ¹ì„± ì¤‘ìš”ë„: {importances.mean():.4f})")
            logger.info(f"í›ˆë ¨ ì™„ë£Œ - íŠ¹ì„± ì¤‘ìš”ë„: {importances.mean():.4f}")
            
            # í›ˆë ¨ ì •í™•ë„
            train_score = self.model.score(X_train, y_train)
            print(f"   í›ˆë ¨ ì •í™•ë„: {train_score:.4f}")
            
            # ê²€ì¦ ì •í™•ë„ (ìˆëŠ” ê²½ìš°)
            if X_test is not None and y_test is not None:
                test_score = self.model.score(X_test, y_test)
                print(f"   ê²€ì¦ ì •í™•ë„: {test_score:.4f}")
            
        except Exception as e:
            print(f"âŒ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            logger.error(f"í›ˆë ¨ ì‹¤íŒ¨: {e}")
    
    def predict(self, X):
        """ì˜ˆì¸¡"""
        if not self.is_fitted:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return self.model.predict(X)
    
    def predict_proba(self, X):
        """í™•ë¥  ì˜ˆì¸¡"""  
        if not self.is_fitted:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return self.model.predict_proba(X)
    
    def evaluate(self, X_test, y_test):
        """ëª¨ë¸ í‰ê°€"""
        print("\nğŸ“Š ëª¨ë¸ í‰ê°€ ì‹œì‘...")
        
        test_loss = None  # RandomForestëŠ” lossê°€ ì—†ìŒ
        test_accuracy = self.model.score(X_test, y_test)
        
        predictions = self.model.predict(X_test)
        report = classification_report(y_test, predictions, output_dict=True)
        
        results = {
            'test_loss': test_loss,
            'test_accuracy': float(test_accuracy),
            'classification_report': report
        }
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
        print(f"   ì •ë°€ë„: {report['macro avg']['precision']:.4f}")
        print(f"   ì¬í˜„ìœ¨: {report['macro avg']['recall']:.4f}")
        print(f"   F1ì ìˆ˜: {report['macro avg']['f1-score']:.4f}")
        
        logger.info(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
        return results
    
    def save_model(self, save_path):
        """ëª¨ë¸ ì €ì¥"""
        # ëª¨ë¸ ì €ì¥ (pickle ì‚¬ìš©)
        with open(f"{save_path}_model.pkl", 'wb') as f:
            pickle.dump(self.model, f)
        
        # K-means ëª¨ë¸ë„ ì €ì¥ (ìˆëŠ” ê²½ìš°)
        if self.kmeans is not None:
            with open(f"{save_path}_kmeans.pkl", 'wb') as f:
                pickle.dump(self.kmeans, f)
        
        # ì„¤ì • ì €ì¥
        with open(f"{save_path}_config.json", 'w') as f:
            json.dump(self.config, f, indent=2)
        
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")
        logger.info(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")
    
    def load_model(self, save_path):
        """ëª¨ë¸ ë¡œë“œ"""
        # ëª¨ë¸ ë¡œë“œ
        with open(f"{save_path}_model.pkl", 'rb') as f:
            self.model = pickle.load(f)
        
        # K-means ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        kmeans_path = f"{save_path}_kmeans.pkl"
        if os.path.exists(kmeans_path):
            with open(kmeans_path, 'rb') as f:
                self.kmeans = pickle.load(f)
        
        # ì„¤ì • ë¡œë“œ
        with open(f"{save_path}_config.json", 'r') as f:
            self.config = json.load(f)
        
        self.is_fitted = True
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {save_path}")
        logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {save_path}")


class M4ModelEvaluator:
    """M4 Mac ìµœì í™” í‰ê°€ê¸°"""
    
    def __init__(self, save_plots=True):
        self.save_plots = save_plots
        self.plot_dir = "m4_model_plots"
        
        if save_plots and not os.path.exists(self.plot_dir):
            os.makedirs(self.plot_dir)
        
        print(f"ğŸ“ˆ M4 Mac í‰ê°€ê¸° ì´ˆê¸°í™” (ê·¸ë˜í”„ ì €ì¥: {save_plots})")
    
    def evaluate_model(self, model, X_test, y_test):
        """ì „ì²´ í‰ê°€ ìˆ˜í–‰"""
        # ì˜ˆì¸¡
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)
        
        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True)
        
        print(f"âœ… ì •í™•ë„: {accuracy:.4f}")
        print(f"   ì •ë°€ë„: {report['macro avg']['precision']:.4f}")
        print(f"   ì¬í˜„ìœ¨: {report['macro avg']['recall']:.4f}")
        print(f"   F1ì ìˆ˜: {report['macro avg']['f1-score']:.4f}")
        
        # ì‹œê°í™”
        try:
            self.plot_confusion_matrix(y_test, y_pred)
            self.plot_class_distribution(y_test, y_pred)
            self.plot_metrics(report)
            
        except Exception as e:
            print(f"âš ï¸  ì‹œê°í™” ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        
        return {
            'accuracy': accuracy,
            'classification_report': report,
            'total_samples': len(y_test),
            'num_classes': len(np.unique(y_test))
        }
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """í˜¼ë™ í–‰ë ¬ ê·¸ë˜í”„"""
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'shrink': 0.8})
        plt.title('Confusion Matrix (M4 Mac)', fontsize=14, fontweight='bold')
        plt.xlabel('Predicted Label')
        plt.ylabel('True Label')
        
        if self.save_plots:
            plt.savefig(f"{self.plot_dir}/confusion_matrix.png", dpi=150, bbox_inches='tight')
            print(f"   ğŸ’¾ í˜¼ë™ í–‰ë ¬ ì €ì¥ë¨")
        
        plt.show()
        plt.close()
    
    def plot_class_distribution(self, y_true, y_pred):
        """í´ë˜ìŠ¤ ë¶„í¬ ë¹„êµ"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # ì‹¤ì œ ë¶„í¬
        unique_true, counts_true = np.unique(y_true, return_counts=True)
        ax1.pie(counts_true, labels=[f'Class {i}' for i in unique_true], 
               autopct='%1.1f%%', startangle=90)
        ax1.set_title('True Label Distribution', fontweight='bold')
        
        # ì˜ˆì¸¡ ë¶„í¬
        unique_pred, counts_pred = np.unique(y_pred, return_counts=True)
        ax2.pie(counts_pred, labels=[f'Class {i}' for i in unique_pred], 
               autopct='%1.1f%%', startangle=90)
        ax2.set_title('Predicted Label Distribution', fontweight='bold')
        
        plt.suptitle('Class Distribution Comparison (M4 Mac)', fontsize=16, fontweight='bold')
        
        if self.save_plots:
            plt.savefig(f"{self.plot_dir}/class_distribution.png", dpi=150, bbox_inches='tight')
            print(f"   ğŸ’¾ í´ë˜ìŠ¤ ë¶„í¬ ì €ì¥ë¨")
        
        plt.show()
        plt.close()
    
    def plot_metrics(self, report):
        """í‰ê°€ ì§€í‘œ ë§‰ëŒ€ ê·¸ë˜í”„"""
        metrics = ['precision', 'recall', 'f1-score']
        values = [report['macro avg'][metric] for metric in metrics]
        
        plt.figure(figsize=(10, 6))
        bars = plt.bar(metrics, values, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)
        
        # ê°’ í‘œì‹œ
        for bar, value in zip(bars, values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.title('Model Performance Metrics (M4 Mac)', fontsize=14, fontweight='bold')
        plt.ylabel('Score')
        plt.ylim(0, 1)
        plt.grid(True, alpha=0.3)
        
        if self.save_plots:
            plt.savefig(f"{self.plot_dir}/metrics.png", dpi=150, bbox_inches='tight')
            print(f"   ğŸ’¾ ì„±ëŠ¥ ì§€í‘œ ì €ì¥ë¨")
        
        plt.show()
        plt.close()


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸš€ M4 ëª¨ë¸ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    
    # ë”ë¯¸ ì„ë² ë”© ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
    print("ğŸ”§ í…ŒìŠ¤íŠ¸ ì„ë² ë”© ë°ì´í„° ìƒì„±...")
    dummy_embeddings = np.random.randn(100, 512)  # 100ê°œ ìƒ˜í”Œ, 512ì°¨ì›
    dummy_labels = np.random.randint(0, 5, 100)   # 5ê°œ í´ë˜ìŠ¤
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = M4TransformerModel()
    
    # ë°ì´í„° ì¤€ë¹„
    X_train, X_test, y_train, y_test = model.prepare_data(
        dummy_embeddings, dummy_labels
    )
    
    # í›ˆë ¨
    model.train(X_train, y_train, X_test, y_test)
    
    # í‰ê°€
    results = model.evaluate(X_test, y_test)
    print("\nğŸ“Š í‰ê°€ ê²°ê³¼:", results)
    
    # í‰ê°€ê¸° ì‚¬ìš©
    evaluator = M4ModelEvaluator(save_plots=True)
    detailed_results = evaluator.evaluate_model(model, X_test, y_test)
    
    # ëª¨ë¸ ì €ì¥
    model.save_model("m4_test_model")
    
    print("\nğŸ‰ M4 ëª¨ë¸ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
# import tensorflow as tf
# from tensorflow import keras
# from tensorflow.keras import layers
# import numpy as np
# import pickle
# import logging
# from sklearn.model_selection import train_test_split
# from sklearn.cluster import KMeans
# import json
# from datetime import datetime
# import os

# logger = logging.getLogger(__name__)


# class TransformerModel:
#     """ì„ë² ë”© ë°ì´í„°ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ í•™ìŠµ"""
    
#     def __init__(self, embedding_dim=512, num_heads=8, ff_dim=2048, num_layers=4):
#         """ëª¨ë¸ ì„¤ì • ì´ˆê¸°í™”"""
#         self.embedding_dim = embedding_dim
#         self.num_heads = num_heads
#         self.ff_dim = ff_dim
#         self.num_layers = num_layers
#         self.model = None
#         self.history = None
    
#     def load_embeddings(self, embeddings_path, data_path=None):
#         """ì €ì¥ëœ ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
#         embeddings = np.load(embeddings_path)
#         logger.info(f"ì„ë² ë”© ë¡œë“œ: {embeddings.shape}")
        
#         metadata = None
#         if data_path and os.path.exists(data_path):
#             with open(data_path, 'rb') as f:
#                 metadata = pickle.load(f)
#             logger.info(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(metadata['texts'])}ê°œ")
        
#         return embeddings, metadata
    
#     def create_transformer_block(self, embed_dim, num_heads, ff_dim):
#         """íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ ìƒì„±"""
#         inputs = layers.Input(shape=(None, embed_dim))
        
#         # Multi-Head Attention : ë¬¸ì¥ ë‚´ ë‹¨ì–´ë“¤ ê°„ì˜ ê´€ê³„ í•™ìŠµ
#         attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
#         attention_output = attention(inputs, inputs) #self-atteintion : ìê¸° ìì‹ ê³¼ ì–´í…ì…˜
#         attention_output = layers.Dropout(0.1)(attention_output)
#         out1 = layers.LayerNormalization()(inputs + attention_output)
        
#         # Feed Forward Network
#         #í™•ì¥: "ì´ ë¬¸ì¥ì— ëŒ€í•´ ì—¬ëŸ¬ ê°ë„ë¡œ ìƒê°í•´ë³´ì" (ë” ë§ì€ ë‰´ëŸ° í™œìš©)
#         #ReLU: "í•„ìš” ì—†ëŠ” ìƒê°ì€ ë²„ë¦¬ì" (ìŒìˆ˜ ì œê±°)
#         #ì••ì¶•: "í•µì‹¬ë§Œ ì •ë¦¬í•´ì„œ ê²°ë¡ ë‚´ì" (ì›ë˜ í¬ê¸°ë¡œ)
#         # 512 > 2048 ,  ReLU í™œì„±í™” í•¨ìˆ˜: ìŒìˆ˜ëŠ” 0, ì–‘ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ
#         ffn_output = layers.Dense(ff_dim, activation="relu")(out1)
#         # 2048 > 512, í™œì„±í™” í•¨ìˆ˜ ì—†ì´ ì„ í˜• ë³€í™˜
#         ffn_output = layers.Dense(embed_dim)(ffn_output)
#         ffn_output = layers.Dropout(0.1)(ffn_output)
#         out2 = layers.LayerNormalization()(out1 + ffn_output)
        
#         return keras.Model(inputs=inputs, outputs=out2)
    
#     def build_model(self, num_classes):
#         """ì „ì²´ ëª¨ë¸ êµ¬ì„±"""
#         inputs = layers.Input(shape=(1, self.embedding_dim))
        
#         # íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ë“¤
#         x = inputs
#         for _ in range(self.num_layers):
#             transformer = self.create_transformer_block(
#                 self.embedding_dim, self.num_heads, self.ff_dim
#             )
#             x = transformer(x)
        
#         # ë¶„ë¥˜ í—¤ë“œ
#         x = layers.GlobalAveragePooling1D()(x)
#         x = layers.Dropout(0.1)(x)
#         x = layers.Dense(512, activation="relu")(x)
#         x = layers.Dropout(0.1)(x)
#         outputs = layers.Dense(num_classes, activation="softmax")(x)
        
#         self.model = keras.Model(inputs=inputs, outputs=outputs)
        
#         # ì»´íŒŒì¼
#         self.model.compile(
#             optimizer=keras.optimizers.Adam(learning_rate=1e-4),
#             loss="sparse_categorical_crossentropy",
#             metrics=["accuracy"]
#         )
        
#         logger.info(f"ëª¨ë¸ êµ¬ì„± ì™„ë£Œ - íŒŒë¼ë¯¸í„°: {self.model.count_params():,}ê°œ")
    
#     def prepare_data(self, embeddings, labels=None, test_size=0.2):
#         """í•™ìŠµ ë°ì´í„° ì¤€ë¹„"""
#         # ì„ë² ë”©ì„ (batch, 1, dim) í˜•íƒœë¡œ ë³€í™˜
#         X = embeddings.reshape(embeddings.shape[0], 1, embeddings.shape[1])
        
#         # ë¼ë²¨ì´ ì—†ìœ¼ë©´ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ìƒì„±
#         if labels is None:
#             n_clusters = min(10, len(X) // 10)
#             kmeans = KMeans(n_clusters=n_clusters, random_state=42)
#             labels = kmeans.fit_predict(embeddings)
#             logger.info(f"í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ {n_clusters}ê°œ í´ë˜ìŠ¤ ìƒì„±")
        
#         # ë°ì´í„° ë¶„í• 
#         X_train, X_test, y_train, y_test = train_test_split(
#             X, labels, test_size=test_size, random_state=42, stratify=labels
#         )
        
#         logger.info(f"í›ˆë ¨: {X_train.shape[0]}ê°œ, í…ŒìŠ¤íŠ¸: {X_test.shape[0]}ê°œ")
#         return X_train, X_test, y_train, y_test
    
#     def train(self, X_train, y_train, X_test=None, y_test=None, epochs=50, batch_size=32):
#         """ëª¨ë¸ í›ˆë ¨"""
#         if self.model is None:
#             num_classes = len(np.unique(y_train))
#             self.build_model(num_classes)
        
#         # ì½œë°± ì„¤ì •
#         callbacks = [
#             keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
#             keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)
#         ]
        
#         validation_data = (X_test, y_test) if X_test is not None else None
        
#         logger.info("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
#         self.history = self.model.fit(
#             X_train, y_train,
#             batch_size=batch_size,
#             epochs=epochs,
#             validation_data=validation_data,
#             callbacks=callbacks,
#             verbose=1
#         )
#         logger.info("í›ˆë ¨ ì™„ë£Œ")
    
#     def evaluate(self, X_test, y_test):
#         """ëª¨ë¸ í‰ê°€"""
#         test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)
        
#         predictions = self.model.predict(X_test, verbose=0)
#         predicted_classes = np.argmax(predictions, axis=1)
        
#         from sklearn.metrics import classification_report
#         report = classification_report(y_test, predicted_classes, output_dict=True)
        
#         results = {
#             'test_loss': float(test_loss),
#             'test_accuracy': float(test_accuracy),
#             'classification_report': report
#         }
        
#         logger.info(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
#         return results
    
#     def save_model(self, save_path):
#         """ëª¨ë¸ ì €ì¥"""
#         self.model.save(f"{save_path}_model.h5")
        
#         config = {
#             'embedding_dim': self.embedding_dim,
#             'num_heads': self.num_heads,
#             'ff_dim': self.ff_dim,
#             'num_layers': self.num_layers,
#             'timestamp': datetime.now().isoformat()
#         }
        
#         with open(f"{save_path}_config.json", 'w') as f:
#             json.dump(config, f, indent=2)
        
#         logger.info(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")


# # ì‚¬ìš© ì˜ˆì‹œ
# if __name__ == "__main__":
#     logging.basicConfig(level=logging.INFO)
    
#     # ëª¨ë¸ ì´ˆê¸°í™”
#     model = TransformerModel()
    
#     # ë°ì´í„° ë¡œë“œ
#     embeddings, metadata = model.load_embeddings(
#         "training_embeddings_embeddings.npy",
#         "training_embeddings_data.pkl"
#     )
    
#     # ë°ì´í„° ì¤€ë¹„
#     X_train, X_test, y_train, y_test = model.prepare_data(embeddings)
    
#     # í›ˆë ¨
#     model.train(X_train, y_train, X_test, y_test)
    
#     # í‰ê°€
#     results = model.evaluate(X_test, y_test)
#     print("í‰ê°€ ê²°ê³¼:", results)
    
#     # ì €ì¥
#     model.save_model("trained_transformer")
